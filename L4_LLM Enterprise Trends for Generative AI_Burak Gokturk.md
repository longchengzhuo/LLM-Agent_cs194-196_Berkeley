## 1. 神经网络的崛起
*
    *   早期对神经网络的质疑，当时支持向量机和决策树等传统算法表现更好。
    *   神经网络之所以变得优秀的原因：
        *   **架构上的可并行化**，相较于当时的许多其他算法更容易并行处理。
        *   **海量训练数据集的需求**，并行化需要大量数据才能发挥作用。
        *   **Masking技术**的出现解决了训练数据不足的问题，可以通过掩盖句子中的词语并预测它们来创建大量的训练数据。
        *   **GPU和TPU等硬件的巨大进步**加速了训练过程。
        *   **Transformer架构**的引入带来了算法上的显著改进。
## 2. 企业AI趋势
*  
    *   基础大型模型的改进速度很快，可能超过领域特定模型。
    *   **高效稀疏模型**的兴起，提高了推理速度并降低了成本。
    *   **多模态模型**成为趋势，能够理解和生成各种类型的数据（图像、文本、音频、视频等）。
    *   企业关注点从选择特定模型转向**选择平台**，因为新模型不断涌现，平台可以提供更广泛的模型选择和灵活性。
    *   **管理这些模型的能力**对于企业至关重要，需要保证高可靠性。
    *   **API成本逐渐接近于零**，尽管开源模型的总体成本可能更高。
    *   **延迟降低**，使得更多对延迟敏感的应用成为可能。
    *   **搜索与大型语言模型的结合成为巨大的趋势**，以解决LLM的知识过时和幻觉问题，并提供引用能力。
## 3. 构建LLM Agent的关键方法
*
    *   **微调 (Tuning)**：使用自有数据针对特定用例优化基础模型。
    *   **知识蒸馏 (Distillation)**：将大型模型的知识转移到更小的模型中，以降低成本和延迟。
    *   **grounding (基础/溯源)**：结合搜索等外部信息来源，使LLM的回答更加真实可靠。
    *   **扩展与函数调用 (Extension and Function Calling)**：使LLM能够调用外部工具和API来执行实际操作。
*   **微调的细节**
    *   不同的微调方法，从Prompt设计到全参数微调。
    *   **Prompt设计 (Prompt Design)**：通过在Prompt中添加少量示例来指导LLM。
    *   **Prompt调优 (Prompt Tuning)**：通过学习一个可以添加到LLM的嵌入向量来影响其行为。
    *   **传统微调 (Conventional Fine-tuning)**：更新模型的所有或大部分权重，需要大量计算资源和数据。
    *   **参数高效微调 (Parameter Efficient Fine-tuning)**：仅更新模型的一小部分参数或添加额外的层，减少了计算需求和数据量，例如**LoRA (Low-Rank Adaptation)**。
---
## _如果 ΔW 是满秩的，使用LoRA是否会导致效果不好。_

- **什么是满秩？**  
  一个矩阵 ΔW（假设其维度为 \( d \times k \)）是满秩的，意味着它的秩等于 \(\min(d, k)\)。此时，ΔW 的信息无法通过更低维的表示来完全重构，因为它的每一行（或列）都包含独立的信息，没有冗余。

- **LoRA在满秩情况下的表现**  
  LoRA通过低秩分解 \( \Delta W \approx A \cdot B \) 来近似 ΔW，其中 \( A \) 和 \( B \) 的秩 \( r \) 是预先设定的超参数，且 \( r < \min(d, k) \)。如果 ΔW 是满秩的，而 \( r \) 小于其实际秩，那么低秩近似必然会丢失一部分信息。这是因为低秩矩阵无法完全捕捉满秩矩阵的所有独立方向，导致精度损失。

- **你的表述是否准确？**  
  你提到“当 ΔW 是满秩的，换句话说 ΔW 不应该被损失精度，如果你使用LoRA，就会导致效果不好”。这里的逻辑基本正确，但可以稍作 уточнение（澄清）：  
  - 如果 ΔW 是满秩的，并且任务要求保留 ΔW 的全部信息（即不允许精度损失），那么使用LoRA确实会导致性能下降。因为LoRA的低秩近似无法完整表示满秩的 ΔW。  
  - 在这种情况下，全参数微调（直接更新整个 ΔW）会比LoRA更合适，因为它不会限制 ΔW 的秩。

- **实际情况如何？**  
  虽然理论上满秩的 ΔW 会让LoRA的效果变差，但在实践中，这种情况不一定常见。研究表明，在许多微调任务中，ΔW 的有效秩通常远低于其最大可能秩。**这可能是因为微调任务与预训练任务有一定的关联性**，模型只需要在少数方向上调整权重，而不需要全面更新。即使 ΔW 在理论上可以是满秩的，其主要信息往往集中在低秩部分，LoRA仍然能够以较小的代价取得接近全参数微调的性能。
---
*   **知识蒸馏的细节**
    *   使用**教师-学生模型**的方法，教师模型（大型模型）生成标签（可以是软标签），学生模型（小型模型）从中学习。
    *   使用**温度系数 (Temperature)** 来平滑Softmax输出，生成更丰富的软标签。
---
## _ai学生应该由ai老师来教，而不是人类老师_
### 在讨论大模型蒸馏（Distillation）领域时，从第一性原理出发，我们可能会觉得用一个更小的模型（学生模型）达到与大模型（教师模型）同样的性能是不合理的。毕竟，小型模型的参数量和计算能力有限，怎么可能完全复制大型模型的表现呢？然而，蒸馏技术在实践中却能显著提升小型模型的性能，这背后一定有其潜在假设和理论依据。那么，这种学生-教师模型的潜在假设是什么？为什么这种方法能够奏效？

蒸馏技术的核心潜在假设是：大型模型学到的知识中包含冗余信息，而小型模型可以通过学习大型模型的“软标签”或“特征表示”，捕获这些知识中最核心、最有用的部分，从而接近大型模型的性能。

具体来说，这一假设可以拆解为以下几点：

* 软标签包含丰富信息

    大型模型在训练时不仅输出硬标签（例如具体的类别），还生成软标签（即类别概率分布）。这些软标签反映了模型对数据的不确定性以及类别之间的相似性。相比于硬标签，软标签提供了更丰富的信息，小型模型通过学习这些软标签，可以更好地理解数据的内在分布，而不仅仅是简单地拟合单一类别。
* 特征表示具有泛化性

    大型模型在训练过程中，其中间层通常会生成具有高度泛化能力的特征表示。这些表示可能比最终的输出更能捕捉数据的本质。小型模型通过模仿教师模型的中间层输出，可以学习到类似的特征表示，从而提升自身的预测能力。
* 大型模型存在冗余

    大型模型通常是过参数化的，它们在训练时学到的知识中包含了大量冗余信息。这些冗余信息可能对训练集的表现有帮助，但对于在新数据上的泛化性能并非必需。小型模型无需复制所有信息，只需聚焦于对任务最重要的部分即可。
---
*   **Grounding的细节**
    *   解决LLM知识过时、幻觉和无法溯源的问题。
    *   常见方法：
        *   **检索增强生成 (Retrieval-Augmented Generation, RAG)**：在生成答案之前，先通过搜索获取相关上下文。
    *   **动态检索 (Dynamic Retrieval)** 的概念，根据LLM的响应智能地决定是否需要调用搜索引擎。
*   **构建成功Agent所需的其他工具**
    *   强大的**Prompt管理系统**，包括存储、版本控制和跨模型转换能力。
    *   **评估工具**，用于比较不同模型的性能，特别是**Auto Side-by-Side**评估，使用大型模型来评估其他模型的输出。


