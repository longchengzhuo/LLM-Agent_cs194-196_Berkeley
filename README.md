# This is my personal study note; the original course syllabus can be found in the table below ([original website](https://rdi.berkeley.edu/llm-agents/f24)). 

## Course Description

Large language models (LLMs) have transformed numerous domains, emerging as powerful agents capable of interacting with the world and managing diverse tasks. With ongoing advancements in LLM techniques, these agents are poised to become the next major breakthrough in artificial intelligence, reshaping daily life through intelligent task automation and personalization. This course explores the foundational concepts critical to LLM agents, including the underpinnings of LLMs, key abilities for task automation, and the infrastructure supporting agent development. We will also examine prominent applications such as code generation, robotics, web automation, medical uses, and scientific discovery. Additionally, the course addresses the limitations and risks of current LLM agents, offering insights into future improvements.

## Course Topics
- Foundation of LLMs
- Reasoning
- Planning and Tool Use
- LLM Agent Infrastructure
- Retrieval-Augmented Generation
- Code Generation and Data Science
- Multimodal Agents and Robotics
- Evaluation and Benchmarking of Agent Applications
- Privacy, Safety, and Ethics
- Human-Agent Interaction, Personalization, and Alignment
- Multi-Agent Collaboration

---

# Syllabus

| **Date**      | **Topic**                                           | **Guest Lecturer**                  | **Readings (Due Sunday 11:59 PM before lecture on Gradescope)**                                                                                   |
|----------------|----------------------------------------------------|-------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------|
| **Sept 9**    | LLM Reasoning                                      | Denny Zhou, Google DeepMind         | - Chain-of-Thought Reasoning Without Prompting<br>- Large Language Models Cannot Self-Correct Reasoning Yet<br>- Premise Order Matters in Reasoning with Large Language Models<br>- Chain-of-Thought Empowers Transformers to Solve Inherently Serial Problems<br>*All readings optional this week.* |
| **Sept 16**   | LLM Agents: Brief History and Overview             | Shunyu Yao, OpenAI                  | - WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents<br>- ReAct: Synergizing Reasoning and Acting in Language Models |
| **Sept 23**   | Agentic AI Frameworks & AutoGen<br>Building a Multimodal Knowledge Assistant | Chi Wang, AutoGen-AI<br>Jerry Liu, LlamaIndex | - AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation<br>- StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows |
| **Sept 30**   | Enterprise Trends for Generative AI and Key Components of Successful Agents | Burak Gokturk, Google              | - Google Cloud Expands Grounding Capabilities on Vertex AI<br>- The Needle In a Haystack Test: Evaluating the Performance of RAG Systems<br>- The AI Detective: The Needle in a Haystack Test and How Gemini 1.5 Pro Solves It |
| **Oct 7**     | Compound AI Systems & the DSPy Framework           | Omar Khattab, Databricks            | - Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs<br>- Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together |
| **Oct 14**    | Agents for Software Development                    | Graham Neubig, Carnegie Mellon University | - SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering<br>- OpenHands: An Open Platform for AI Software Developers as Generalist Agents |
| **Oct 21**    | AI Agents for Enterprise Workflows                 | Nicolas Chapados, ServiceNow        | - WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?<br>- WorkArena++: Towards Compositional Planning and Reasoning-based Common Knowledge Work Tasks<br>- TapeAgents: A Holistic Framework for Agent Development and Optimization |
| **Oct 28**    | Towards a Unified Framework of Neural and Symbolic Decision Making | Yuandong Tian, Meta AI (FAIR)      | - Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping<br>- Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces<br>- Composing Global Optimizers to Reasoning Tasks via Algebraic Objects in Neural Nets<br>- SurCo: Learning Linear Surrogates For Combinatorial Nonlinear Optimization Problems |
| **Nov 4**     | Project GR00T: A Blueprint for Generalist Robotics | Jim Fan, NVIDIA                     | - Voyager: An Open-Ended Embodied Agent with Large Language Models<br>- Eureka: Human-Level Reward Design via Coding Large Language Models<br>- DrEureka: Language Model Guided Sim-To-Real Transfer |
| **Nov 11**    | No Class - Veterans Day                            |                                     |                                                                                                                                                  |
| **Nov 18**    | Open-Source and Science in the Era of Foundation Models | Percy Liang, Stanford University   | - Cybench: A Framework for Evaluating Cybersecurity Capabilities and Risks of Language Models                                                  |
| **Nov 25**    | Measuring Agent Capabilities and Anthropicâ€™s RSP   | Ben Mann, Anthropic                 | - Announcing Our Updated Responsible Scaling Policy<br>- Developing a Computer Use Model                                                          |
| **Dec 2**     | Towards Building Safe & Trustworthy AI Agents and a Path for Science- and Evidence-Based AI Policy | Dawn Song, UC Berkeley             | - A Path for Science- and Evidence-Based AI Policy<br>- DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models<br>- Representation Engineering: A Top-Down Approach to AI Transparency<br>- Extracting Training Data from Large Language Models<br>- The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks<br>*All readings optional this week.* |

---